%==============================================================================
\chapter{Introduction}
\label{sec:intro}
%==============================================================================

Leukipp (450–370 B.C.) and Demokrit (460–371 B.C.) were most likely the first humans that postulated that matter is composed of indivisible objects. Even though our knowledge about matter has been greatly improved ever since then, the fundamental statement still holds up. Our current understanding of the elementary particles and fundamental forces in our universe is described by the Standard Model of particle physics (SM). It is the unification of many profound theoretical ideas which are capable of explaining almost all observed phenomena. \\
The SM's heaviest elementary particle is the top quark with a mass close to that of a gold atom. Due to its high mass, plays the top quark a special role in the search for beyond the Standard Model physics. When four top quarks are produced in a single proton-proton collision with an energy of over $\SI{700}{GeV}$, they create the heaviest particle final state ever seen at any particle collider. The simultaneous production of four top quarks is an incredibly rare process which makes it interesting to study and hard to observe. Reason enough to investigate this process with new techniques such as Deep Neural Networks. \\
Deep Neural Networks are the models used in deep learning which over the passed decade has developed to most flexible and widely applied machine learning field. In recent years Deep Neural Networks have become the go-to machine learning technique for speech recognition, spam filters, self driving cars and many other applications. With the high Luminosity upgrade of the Large Hadron Collider the number of observed events will increase largely. Making Deep Neural Networks which performance scale very well with the amount of available data to the very promising prospect. \\
This thesis uses the four-top-quark process as a framework to investigate how suitable Deep Neural Networks are for event classification for rare processes. Feedforward Neural Networks will be used to investigate both the achievable performance and the dominant and hard to distinguishing backgrounds. Recurrent Neural Networks with raw kinematic information will be used to investigate if the Neural Network can construct better features than humas can. For better rejection of backgrounds, which are hard to distinguish from the four-top-quark process, a hadronic top quark reconstruction is carried out. \\
The chapters are organized as follows: Chapter \ref{sec:theory} briefly introduces the Standard Model of particle physics and the four-top-quark production. In Chapter \ref{sec:ATLAS}, a short overview of the Large Hadron Collider and the ATLAS experiment is given. The utilized datasets and their simulation is discussed in Chapter \ref{sec:Samples}. Chapter \ref{sec:Deep_learning} gives a brief introduction to deep learning and different types of Neural Networks. The setup up as well as the first studies of Neural Networks are introduced in Chapter \ref{sec:NNSetup}. The last chapter (Chapter \ref{sec:Results}) presents the results of the Neural Network studies and a reconstruction of hadronically decaying top quarks. \\
The terminology of particles physics and deep learning is different. For instance are datasets commonly called samples and features variables. In this thesis the phrase coming from deep learing will be used unless a physics concept is introduced. For obvious reasons will the instances of data be called \textit{events}.

